\documentclass[a4paper,10pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{enumitem}
\renewcommand{\baselinestretch}{1.2}
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    citecolor=black,
    filecolor=black,
    urlcolor=blue
}

\begin{document}

\begin{center}
    {\LARGE \textbf{Marcelo Biagi Martins}} \\
    {\large \textbf{Data Engineer}} \\
    \textbf{Location:} Jundiai, Sao Paulo, Brazil \textbar \hspace{0.1em} \textbf{Phone:} +55 11 95038-8267 \\
    \textbf{Email:} \href{mailto:marcelobmartins219@hotmail.com}{marcelobmartins219@hotmail.com} \\
    \textbf{LinkedIn:} \href{https://www.linkedin.com/in/marcelo-biagi-martins-aa5a7616b/}{linkedin.com/in/marcelobiagimartins} \\
\end{center}

\hrule
\vspace{1em}

\section*{Summary}
Data Engineer and Technology Consultant with over 5 years of experience in designing and implementing data ecosystems. Expertise in leading high-performance teams to build scalable architectures, optimizing pipelines and queries, and implementing cloud solutions. Proficient in translating business needs into actionable data solutions and ensuring high-quality deliverables. Experienced in leading technical initiatives and fostering collaboration between technical and non-technical stakeholders. Adept at leveraging industry-leading tools such as AWS, Azure, Python and SQL to create state-of-art end products.

\section*{Skills}
\begin{itemize}[leftmargin=*]
    \item \textbf{Version Control:} Git (repository management, collaboration, version tracking)
    \item \textbf{Programming:} Python, SQL
    \item \textbf{Data Engineering Tools:} AWS S3, AWS Athena, AWS Glue, AWS Redshift, AWS QuickSight, Hadoop, Hive, Impala, ETL, Alteryx, Azure Data Factory, Databricks, Azure Data Lake, Docker, Airflow, PySpark, Parquet
    \item \textbf{Data Modeling:} Star Schema, Snowflake Schema
    \item \textbf{Data Architecture:} Scalable and high-performance cloud architectures, data lakes, data warehouses, data pipelines
    \item \textbf{RPA Tools:} UiPath, APIs, SAP Scripting
    \item \textbf{Cloud Platforms:} Amazon AWS, Microsoft Azure
    \item \textbf{Other Skills:} SQL performance optimization, pipeline testing, data troubleshooting, semantic layer development
    \item \textbf{Languages:} Portuguese (Native), English (Fluent)
\end{itemize}

\section*{Professional Experience}

\noindent
\makebox[5cm][l]{\textbf{Data Engineer}} Visagio Technology, Remote \hfill December/2020 -- Present
\begin{itemize}[leftmargin=*]
    \item \textbf{Client: Global Chemical Industry}: Led the technical development of a fully automated data pipeline and model to support a dashboard previously maintained manually by the business team using Excel and SAP extractions. Managed a team of 3 people to design and build tables, views, and refine the data model using the Azure ecosystem (SQL Data Studio, Data Lake, Data Factory), Databricks, Unity Catalog, PySpark, and Python. Reduced data extraction time from 15 days to daily updates, ensuring real-time numbers on the dashboard and enabling a seamless, automated reporting process.
    \item \textbf{Client: Major Latin American Bank}: Led the technical transition of a core business area from on-premise infrastructure to the cloud, managing a team of 4 people responsible for migrating, optimizing, and creating pipelines. Leveraged Hadoop, SAS, Alteryx, SQL, PySpark, and the AWS ecosystem (S3, Glue, Athena, Redshift, QuickSight, EventBridge) to automate workflows that previously required an average of 40 hours, achieving a 90\% reduction in execution time to just 4 hours while optimizing all key queries. Implemented historical tracking, validations, and logging for enhanced reliability, and trained the business team to ensure knowledge transfer and seamless adoption of the new technology stack.
    \item \textbf{Client: Non Governmental Organization}: Led the creation of a cloud-based data infrastructure for a small organization without an IT department, migrating manual Excel-based processes to Azure, starting with a research project on full-time high school education. Utilized the Azure ecosystem, Python, Pandas, and PySpark to develop scalable solutions. Managed a technical team of 3 people, reducing report update times from days to minutes, while maintaining annual costs below 2,000 BRL using Azure's free quota for non-profits.
\end{itemize}

\noindent
\makebox[7cm][l]{\textbf{Research \& Development Intern}} Unilever, Remote \hfill March/2020 -- December/2020
\begin{itemize}[leftmargin=*]
    \item Migrated health records data across Latin America using the Microsoft ecosystem, ensuring data accuracy and regulatory compliance. Conducted data analyses to uncover new sales opportunities, directly supporting strategic decision-making and business growth initiatives.
\end{itemize}

\section*{Education}
\textbf{Bachelor's Degree in Computer Engineering} \\ State University of Campinas (UNICAMP), Brazil \hfill March/2016 -- July/2021

\section*{Certifications}
\begin{itemize}[leftmargin=*]
    \item AWS Data Engineer Associate \href{https://www.credly.com/badges/40904cd1-1c10-43c5-809a-e4750b2f7ec5/linked_in_profile}{(Link)} \hfill October/2024
\end{itemize}

\section*{Languages}
\begin{itemize}[leftmargin=*]
    \item Portuguese: Native
    \item English: Advanced
\end{itemize}

\end{document}